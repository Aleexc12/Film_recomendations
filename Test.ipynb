{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvporcupine\n",
    "import sounddevice as sd\n",
    "\n",
    "# Configuración de Porcupine con access_key\n",
    "porcupine = pvporcupine.create(\n",
    "    access_key=\"qEcRoI9pyPji4cEIXkMNz4+G34KlNQMO5mouLLJzGsvb5PF5fuaKlg==\",  # Reemplaza con tu clave de acceso\n",
    "    keyword_paths=[\"resources/wakeword.ppn\"],\n",
    "    model_path=\"resources/porcupine_params_es.pv\" \n",
    ")\n",
    "\n",
    "def wake_word_detected():\n",
    "    print(\"Wake word detectado. Escuchando tu comando...\")\n",
    "import numpy as np\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if len(indata) != porcupine.frame_length:\n",
    "        print(f\"Ajustando frame length. Original: {len(indata)}, esperado: {porcupine.frame_length}\")\n",
    "        # Interpolamos para ajustar el tamaño del frame\n",
    "        factor = porcupine.frame_length / len(indata)\n",
    "        indata = np.interp(\n",
    "            np.arange(0, len(indata) * factor) / factor,  # Nuevas posiciones\n",
    "            np.arange(len(indata)),  # Posiciones originales\n",
    "            indata[:, 0]  # Solo el primer canal\n",
    "        ).astype(\"int16\")\n",
    "\n",
    "    pcm = indata  # Ya está ajustado\n",
    "    keyword_index = porcupine.process(pcm)\n",
    "    if keyword_index >= 0:\n",
    "        wake_word_detected()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el modelo de Whisper\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    print(\"Escuchando comando...\")\n",
    "    duration = 5  # Duración en segundos\n",
    "    audio = sd.rec(int(duration * 16000), samplerate=16000, channels=1, dtype='float32')\n",
    "    sd.wait()  # Esperar a que termine la grabación\n",
    "    \n",
    "    # Guardar el audio en un archivo temporal\n",
    "    np.save(\"audio_temp.npy\", audio)\n",
    "    print(\"Transcribiendo...\")\n",
    "    \n",
    "    # Usar Whisper para convertir audio a texto\n",
    "    result = model.transcribe(\"audio_temp.npy\", language=\"es\")\n",
    "    return result['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_command(command):\n",
    "    print(f\"Comando recibido: {command}\")\n",
    "    genre = None\n",
    "    runtime = None\n",
    "\n",
    "    # Ejemplo de procesamiento básico\n",
    "    if \"amor\" in command:\n",
    "        genre = \"romance\"\n",
    "    if \"menos de 1:30\" in command or \"corta\" in command:\n",
    "        runtime = 90\n",
    "\n",
    "    return {\n",
    "        \"genre\": genre,\n",
    "        \"runtime\": runtime\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'adult': False, 'backdrop_path': '/8mjYwWT50GkRrrRdyHzJorfEfcl.jpg', 'genre_ids': [28, 12, 18], 'id': 558449, 'original_language': 'en', 'original_title': 'Gladiator II', 'overview': 'Years after witnessing the death of the revered hero Maximus at the hands of his uncle, Lucius is forced to enter the Colosseum after his home is conquered by the tyrannical Emperors who now lead Rome with an iron fist. With rage in his heart and the future of the Empire at stake, Lucius must look to his past to find strength and honor to return the glory of Rome to its people.', 'popularity': 2557.256, 'poster_path': '/2cxhvwyEwRlysAmRH4iodkvo0z5.jpg', 'release_date': '2024-11-13', 'title': 'Gladiator II', 'video': False, 'vote_average': 6.836, 'vote_count': 341}, {'adult': False, 'backdrop_path': '/18TSJF1WLA4CkymvVUcKDBwUJ9F.jpg', 'genre_ids': [27, 53, 9648], 'id': 1034541, 'original_language': 'en', 'original_title': 'Terrifier 3', 'overview': \"Five years after surviving Art the Clown's Halloween massacre, Sienna and Jonathan are still struggling to rebuild their shattered lives. As the holiday season approaches, they try to embrace the Christmas spirit and leave the horrors of the past behind. But just when they think they're safe, Art returns, determined to turn their holiday cheer into a new nightmare. The festive season quickly unravels as Art unleashes his twisted brand of terror, proving that no holiday is safe.\", 'popularity': 3158.896, 'poster_path': '/l1175hgL5DoXnqeZQCcU3eZIdhX.jpg', 'release_date': '2024-10-09', 'title': 'Terrifier 3', 'video': False, 'vote_average': 6.911, 'vote_count': 994}, {'adult': False, 'backdrop_path': '/90ez6ArvpO8bvpyIngBuwXOqJm5.jpg', 'genre_ids': [35, 18, 10749], 'id': 19404, 'original_language': 'hi', 'original_title': 'दिलवाले दुल्हनिया ले जायेंगे', 'overview': 'Raj is a rich, carefree, happy-go-lucky second generation NRI. Simran is the daughter of Chaudhary Baldev Singh, who in spite of being an NRI is very strict about adherence to Indian values. Simran has left for India to be married to her childhood fiancé. Raj leaves for India with a mission at his hands, to claim his lady love under the noses of her whole family. Thus begins a saga.', 'popularity': 35.89, 'poster_path': '/lfRkUr7DYdHldAqi3PwdQGBRBPM.jpg', 'release_date': '1995-10-20', 'title': 'Dilwale Dulhania Le Jayenge', 'video': False, 'vote_average': 8.5, 'vote_count': 4437}, {'adult': False, 'backdrop_path': '/Adrip2Jqzw56KeuV2nAxucKMNXA.jpg', 'genre_ids': [37], 'id': 429, 'original_language': 'it', 'original_title': 'Il buono, il brutto, il cattivo', 'overview': 'While the Civil War rages on between the Union and the Confederacy, three men – a quiet loner, a ruthless hitman, and a Mexican bandit – comb the American Southwest in search of a strongbox containing $200,000 in stolen gold.', 'popularity': 91.649, 'poster_path': '/bX2xnavhMYjWDoZp1VM6VnU1xwe.jpg', 'release_date': '1966-12-22', 'title': 'The Good, the Bad and the Ugly', 'video': False, 'vote_average': 8.463, 'vote_count': 8597}, {'adult': False, 'backdrop_path': '/sJNNMCc6B7KZIY3LH3JMYJJNH5j.jpg', 'genre_ids': [28, 18], 'id': 346, 'original_language': 'ja', 'original_title': '七人の侍', 'overview': \"A samurai answers a village's request for protection after he falls on hard times. The town needs protection from bandits, so the samurai gathers six others to help him teach the people how to defend themselves, and the villagers provide the soldiers with food.\", 'popularity': 53.872, 'poster_path': '/iAq0sq42vKTLneVGqHn1D4GzgrM.jpg', 'release_date': '1954-04-26', 'title': 'Seven Samurai', 'video': False, 'vote_average': 8.463, 'vote_count': 3667}, {'adult': False, 'backdrop_path': '/7lyq8hK0MhPHpUXdnqbFvZYSfkk.jpg', 'genre_ids': [18, 10749], 'id': 11216, 'original_language': 'it', 'original_title': 'Nuovo Cinema Paradiso', 'overview': \"A filmmaker recalls his childhood, when he fell in love with the movies at his village's theater and formed a deep friendship with the theater's projectionist.\", 'popularity': 36.62, 'poster_path': '/gCI2AeMV4IHSewhJkzsur5MEp6R.jpg', 'release_date': '1988-11-17', 'title': 'Cinema Paradiso', 'video': False, 'vote_average': 8.4, 'vote_count': 4361}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL del servidor Flask\n",
    "BASE_URL = \"http://127.0.0.1:5000\"\n",
    "\n",
    "# Obtener la lista de seguimiento (después de autenticarse)\n",
    "response = requests.get(f\"{BASE_URL}/get_watchlist\")\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_wake_word():\n",
    "    def audio_callback(indata, frames, time, status):\n",
    "        if status:\n",
    "            print(f\"Estado del stream: {status}\")\n",
    "        \n",
    "        # Verifica si el tamaño del frame es correcto\n",
    "        if len(indata) == porcupine.frame_length:\n",
    "            pcm = indata[:, 0]  # Procesa solo el canal mono\n",
    "            keyword_index = porcupine.process(pcm)\n",
    "            if keyword_index >= 0:\n",
    "                wake_word_detected()\n",
    "        else:\n",
    "            print(f\"Frame length inválido: esperado {porcupine.frame_length}, recibido {len(indata)}\")\n",
    "\n",
    "    # Configurar el flujo de audio con blocksize\n",
    "    with sd.InputStream(\n",
    "        callback=audio_callback,\n",
    "        channels=1,  # Mono\n",
    "        samplerate=porcupine.sample_rate,  # 16000 Hz\n",
    "        blocksize=porcupine.frame_length,  # Asegurar el tamaño del bloque\n",
    "        dtype=\"int16\",  # Formato esperado por Porcupine\n",
    "    ):\n",
    "        print(\"Escuchando activación...\")\n",
    "        while True:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando el sistema de detección de wake word...\n",
      "Escuchando activación...\n",
      "Wake word detectado. Preparando para escuchar el comando...\n",
      "Grabando audio por 5 segundos...\n",
      "Grabación completada.\n",
      "Audio guardado en c:\\Users\\alexc\\OneDrive - Universidad Politécnica de Madrid\\Escritorio\\CDIA\\Proyectos\\Film_recomendations\\temp_audio.wav\n",
      "Sistema de detección finalizado.\n"
     ]
    }
   ],
   "source": [
    "import pvporcupine\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "\n",
    "DEVICE_INDEX = 5  # Ajustar al índice correcto según tu micrófono\n",
    "running = True  # Bandera para controlar el bucle principal\n",
    "\n",
    "# Configuración de Porcupine\n",
    "try:\n",
    "    porcupine = pvporcupine.create(\n",
    "        access_key=\"qEcRoI9pyPji4cEIXkMNz4+G34KlNQMO5mouLLJzGsvb5PF5fuaKlg==\",\n",
    "        keyword_paths=[\"resources/wakeword.ppn\"],\n",
    "        model_path=\"resources/porcupine_params_es.pv\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error al inicializar Porcupine: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "def wake_word_detected():\n",
    "    global running\n",
    "    print(\"Wake word detectado. Preparando para escuchar el comando...\")\n",
    "    grabar_comando()\n",
    "    running = False  # Detener el bucle principal\n",
    "\n",
    "def grabar_comando():\n",
    "    print(\"Grabando audio por 5 segundos...\")\n",
    "    try:\n",
    "        duration = 5\n",
    "        audio = sd.rec(int(duration * 16000), samplerate=16000, channels=1, dtype='int16', device=DEVICE_INDEX)\n",
    "        sd.wait()\n",
    "        print(\"Grabación completada.\")\n",
    "        \n",
    "        # Guardar el archivo en formato estándar para Whisper\n",
    "        temp_audio_path = \"temp_audio.wav\"\n",
    "        write(temp_audio_path, 16000, audio)\n",
    "        print(f\"Audio guardado en {os.path.abspath(temp_audio_path)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al grabar audio: {e}\")\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(f\"Estado del stream: {status}\")\n",
    "    try:\n",
    "        pcm = indata[:, 0]\n",
    "        keyword_index = porcupine.process(pcm)\n",
    "        if keyword_index >= 0:\n",
    "            wake_word_detected()\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el callback: {e}\")\n",
    "\n",
    "def detect_wake_word():\n",
    "    global running\n",
    "    print(\"Iniciando el sistema de detección de wake word...\")\n",
    "    try:\n",
    "        with sd.InputStream(\n",
    "            device=DEVICE_INDEX,\n",
    "            callback=audio_callback,\n",
    "            channels=1,\n",
    "            samplerate=porcupine.sample_rate,\n",
    "            blocksize=porcupine.frame_length,\n",
    "            dtype=\"int16\",\n",
    "            latency=\"low\"\n",
    "        ) as stream:\n",
    "            print(\"Escuchando activación...\")\n",
    "            while running:\n",
    "                time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterrupción detectada. Finalizando el programa...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el sistema de detección: {e}\")\n",
    "    finally:\n",
    "        porcupine.delete()\n",
    "        print(\"Sistema de detección finalizado.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    detect_wake_word()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo de Whisper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo encontrado: c:\\Users\\alexc\\OneDrive - Universidad Politécnica de Madrid\\Escritorio\\CDIA\\Proyectos\\Film_recomendations\\temp_audio.wav\n",
      "Procesando transcripción...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción: \n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\ffmpeg\\bin\"\n",
    "# Cargar el modelo de Whisper\n",
    "print(\"Cargando modelo de Whisper...\")\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "def transcribe_audio(filename):\n",
    "    \"\"\"Transcribir audio usando Whisper\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Archivo encontrado: {os.path.abspath(filename)}\")\n",
    "        print(\"Procesando transcripción...\")\n",
    "        try:\n",
    "            # Asegúrate de que el archivo está accesible y tiene el formato correcto\n",
    "            result = model.transcribe(filename, language=\"es\")\n",
    "            print(f\"Transcripción: {result['text']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al transcribir el audio: {e}\")\n",
    "    else:\n",
    "        print(f\"Error: El archivo {filename} no existe o no es accesible.\")\n",
    "\n",
    "# Ruta del archivo generado en la parte anterior\n",
    "wav_filename = \"temp_audio.wav\"\n",
    "transcribe_audio(wav_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Películas en la Watchlist:\n",
      "- Gladiator II (2024-11-13): Years after witnessing the death of the revered hero Maximus at the hands of his uncle, Lucius is forced to enter the Colosseum after his home is conquered by the tyrannical Emperors who now lead Rome with an iron fist. With rage in his heart and the future of the Empire at stake, Lucius must look to his past to find strength and honor to return the glory of Rome to its people.\n",
      "- Terrifier 3 (2024-10-09): Five years after surviving Art the Clown's Halloween massacre, Sienna and Jonathan are still struggling to rebuild their shattered lives. As the holiday season approaches, they try to embrace the Christmas spirit and leave the horrors of the past behind. But just when they think they're safe, Art returns, determined to turn their holiday cheer into a new nightmare. The festive season quickly unravels as Art unleashes his twisted brand of terror, proving that no holiday is safe.\n",
      "- Dilwale Dulhania Le Jayenge (1995-10-20): Raj is a rich, carefree, happy-go-lucky second generation NRI. Simran is the daughter of Chaudhary Baldev Singh, who in spite of being an NRI is very strict about adherence to Indian values. Simran has left for India to be married to her childhood fiancé. Raj leaves for India with a mission at his hands, to claim his lady love under the noses of her whole family. Thus begins a saga.\n",
      "- The Good, the Bad and the Ugly (1966-12-22): While the Civil War rages on between the Union and the Confederacy, three men – a quiet loner, a ruthless hitman, and a Mexican bandit – comb the American Southwest in search of a strongbox containing $200,000 in stolen gold.\n",
      "- Seven Samurai (1954-04-26): A samurai answers a village's request for protection after he falls on hard times. The town needs protection from bandits, so the samurai gathers six others to help him teach the people how to defend themselves, and the villagers provide the soldiers with food.\n",
      "- Cinema Paradiso (1988-11-17): A filmmaker recalls his childhood, when he fell in love with the movies at his village's theater and formed a deep friendship with the theater's projectionist.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL del servidor Flask\n",
    "BASE_URL = \"http://127.0.0.1:5000\"\n",
    "\n",
    "# Endpoint para obtener la watchlist\n",
    "endpoint = \"/get_watchlist\"\n",
    "\n",
    "# Hacer la solicitud GET\n",
    "response = requests.get(f\"{BASE_URL}{endpoint}\")\n",
    "\n",
    "# Verificar el resultado\n",
    "if response.status_code == 200:\n",
    "    watchlist = response.json()\n",
    "    print(\"Películas en la Watchlist:\")\n",
    "    for movie in watchlist[\"results\"]:\n",
    "        print(f\"- {movie['title']} ({movie['release_date']}): {movie['overview']}\")\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_genre(transcription):\n",
    "    \"\"\"\n",
    "    Clasifica todos los géneros mencionados en la transcripción a sus IDs correspondientes en TMDb.\n",
    "    \"\"\"\n",
    "    genre_dict = {\n",
    "        \"acción\": 28,\n",
    "        \"aventura\": 12,\n",
    "        \"animación\": 16,\n",
    "        \"comedia\": 35,\n",
    "        \"crimen\": 80,\n",
    "        \"documental\": 99,\n",
    "        \"drama\": 18,\n",
    "        \"familia\": 10751,\n",
    "        \"fantasía\": 14,\n",
    "        \"historia\": 36,\n",
    "        \"terror\": 27,\n",
    "        \"música\": 10402,\n",
    "        \"misterio\": 9648,\n",
    "        \"romance\": 10749,\n",
    "        \"ciencia ficción\": 878,\n",
    "        \"película de tv\": 10770,\n",
    "        \"thriller\": 53,\n",
    "        \"bélico\": 10752,\n",
    "        \"western\": 37\n",
    "    }\n",
    "\n",
    "    transcription = transcription.lower()\n",
    "\n",
    "    # Buscar todos los géneros mencionados\n",
    "    genres_found = [\n",
    "        genre_id for genre_name, genre_id in genre_dict.items()\n",
    "        if genre_name in transcription\n",
    "    ]\n",
    "\n",
    "    return genres_found if genres_found else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Asegúrate de tener este modelo\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "def process_transcription_to_params(transcription):\n",
    "    \"\"\"\n",
    "    Transforma el texto de la transcripción en parámetros para la solicitud.\n",
    "    \"\"\"\n",
    "    transcription = transcription.lower()\n",
    "    \n",
    "    # Inicializar parámetros\n",
    "    params = {\n",
    "        \"vote_count\": None,\n",
    "        \"vote_average\": None,\n",
    "        \"after_year\": None,\n",
    "        \"before_year\": None,\n",
    "        \"adult\": None,\n",
    "        \"language\": None,\n",
    "        \"genre\": None\n",
    "    }\n",
    "    \n",
    "    # Clasificar el género\n",
    "    params[\"genre\"] = classify_genre(transcription)\n",
    "    \n",
    "    # Identificar si es para adultos o familiar\n",
    "    if \"adulto\" in transcription:\n",
    "        params[\"adult\"] = True\n",
    "    elif \"familiar\" in transcription:\n",
    "        params[\"adult\"] = False\n",
    "    \n",
    "    # Procesar números (años y puntuaciones)\n",
    "    nlp_doc = nlp(transcription)\n",
    "    for token in nlp_doc:\n",
    "        if token.like_num:\n",
    "            number = float(token.text)\n",
    "            \n",
    "            # Identificar votación promedio\n",
    "            if any(keyword in transcription for keyword in [\"más de\", \"mayor a\", \"superior a\", \"por encima de\"]):\n",
    "                params[\"vote_average\"] = number\n",
    "            \n",
    "            # Identificar años\n",
    "            if len(token.text) == 4:  # Probable año\n",
    "                if \"antes de\" in transcription:\n",
    "                    params[\"before_year\"] = int(number)\n",
    "                elif \"después de\" in transcription or \"posterior a\" in transcription:\n",
    "                    params[\"after_year\"] = int(number)\n",
    "\n",
    "    # Identificar idioma\n",
    "    if \"español\" in transcription:\n",
    "        params[\"language\"] = \"es\"\n",
    "    elif \"inglés\" in transcription:\n",
    "        params[\"language\"] = \"en\"\n",
    "    elif \"francés\" in transcription:\n",
    "        params[\"language\"] = \"fr\"\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vote_count': None, 'vote_average': 5.0, 'after_year': 2020, 'before_year': None, 'adult': None, 'language': None, 'genre': [28, 878]}\n"
     ]
    }
   ],
   "source": [
    "# Texto de entrada\n",
    "transcription = \"Quiero una película de ciencia ficción o acción que sea de después de 2020 y con una nota superior a 5.\"\n",
    "\n",
    "# Transformar el texto en parámetros\n",
    "params = process_transcription_to_params(transcription)\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'adult': False, 'backdrop_path': '/8mjYwWT50GkRrrRdyHzJorfEfcl.jpg', 'genre_ids': [28, 12, 18], 'id': 558449, 'original_language': 'en', 'original_title': 'Gladiator II', 'overview': 'Years after witnessing the death of the revered hero Maximus at the hands of his uncle, Lucius is forced to enter the Colosseum after his home is conquered by the tyrannical Emperors who now lead Rome with an iron fist. With rage in his heart and the future of the Empire at stake, Lucius must look to his past to find strength and honor to return the glory of Rome to its people.', 'popularity': 2557.256, 'poster_path': '/2cxhvwyEwRlysAmRH4iodkvo0z5.jpg', 'release_date': '2024-11-13', 'title': 'Gladiator II', 'video': False, 'vote_average': 6.836, 'vote_count': 341}, {'adult': False, 'backdrop_path': '/18TSJF1WLA4CkymvVUcKDBwUJ9F.jpg', 'genre_ids': [27, 53, 9648], 'id': 1034541, 'original_language': 'en', 'original_title': 'Terrifier 3', 'overview': \"Five years after surviving Art the Clown's Halloween massacre, Sienna and Jonathan are still struggling to rebuild their shattered lives. As the holiday season approaches, they try to embrace the Christmas spirit and leave the horrors of the past behind. But just when they think they're safe, Art returns, determined to turn their holiday cheer into a new nightmare. The festive season quickly unravels as Art unleashes his twisted brand of terror, proving that no holiday is safe.\", 'popularity': 3158.896, 'poster_path': '/l1175hgL5DoXnqeZQCcU3eZIdhX.jpg', 'release_date': '2024-10-09', 'title': 'Terrifier 3', 'video': False, 'vote_average': 6.911, 'vote_count': 994}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "params = params\n",
    "BASE_URL = \"http://127.0.0.1:5000\"\n",
    "response = requests.get(f\"{BASE_URL}/get_watchlist\", params=params)\n",
    "if response.status_code == 200:\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: comtypes in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyttsx3) (1.4.8)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\alexc\\appdata\\roaming\\python\\python311\\site-packages (from pyttsx3) (306)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alexc\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\alexc\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "inputs = processor(text=\"Hola, mi perro es mono.\", return_tensors=\"pt\")\n",
    "\n",
    "# load xvector containing speaker's voice characteristics from a dataset\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
    "\n",
    "sf.write(\"speech.wav\", speech.numpy(), samplerate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta actual: c:\\Proyectos\\Film_recomendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aba1993071740fe8689af534e71422b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 230467\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import os\n",
    "# Obtener la ruta actual\n",
    "current_path = os.getcwd()\n",
    "print(f\"Ruta actual: {current_path}\")\n",
    "\n",
    "# Especificar el nombre del directorio para guardar/cargar el dataset\n",
    "dataset_path = os.path.join(current_path, \"tokenized_datasets\")\n",
    "\n",
    "# Cargar el dataset tokenizado\n",
    "tokenized_datasets = load_from_disk(dataset_path)\n",
    "print(tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Toma solo una fracción del dataset\n",
    "reduction_factor = 0.01  # Usa solo el 10% del dataset\n",
    "small_dataset = tokenized_datasets.select(range(int(len(tokenized_datasets) * reduction_factor)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando la primera mitad del dataset...\n",
      "Procesando el dataset en GPU (si está disponible)...\n",
      "Preprocesamiento y alineamiento completados.\n",
      "Tamaño del dataset alineado (parte 1): 1152\n",
      "Procesando la segunda mitad del dataset (opcional)...\n",
      "Procesando el dataset en GPU (si está disponible)...\n",
      "Preprocesamiento y alineamiento completados.\n",
      "Validando ejemplos alineados de la primera mitad:\n",
      "Ejemplo 0:\n",
      "input_ids shape: torch.Size([500])\n",
      "labels shape: torch.Size([500, 80])\n",
      "attention_mask shape: torch.Size([500])\n",
      "Ejemplo 1:\n",
      "input_ids shape: torch.Size([500])\n",
      "labels shape: torch.Size([500, 80])\n",
      "attention_mask shape: torch.Size([500])\n",
      "Ejemplo 2:\n",
      "input_ids shape: torch.Size([500])\n",
      "labels shape: torch.Size([500, 80])\n",
      "attention_mask shape: torch.Size([500])\n",
      "Ejemplo 3:\n",
      "input_ids shape: torch.Size([500])\n",
      "labels shape: torch.Size([500, 80])\n",
      "attention_mask shape: torch.Size([500])\n",
      "Ejemplo 4:\n",
      "input_ids shape: torch.Size([500])\n",
      "labels shape: torch.Size([500, 80])\n",
      "attention_mask shape: torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def split_dataset(dataset, num_splits=2):\n",
    "    \"\"\"\n",
    "    Divide un dataset en partes iguales.\n",
    "    \"\"\"\n",
    "    split_size = len(dataset) // num_splits\n",
    "    splits = [dataset[i * split_size: (i + 1) * split_size] for i in range(num_splits)]\n",
    "    if len(dataset) % num_splits != 0:  # Si queda algo al final, lo añadimos a la última parte\n",
    "        splits[-1].extend(dataset[num_splits * split_size:])\n",
    "    return splits\n",
    "\n",
    "def preprocess_and_align(dataset, pad_token_id=0, max_label_length=500):\n",
    "    \"\"\"\n",
    "    Preprocesa y alinea un dataset completo moviendo los tensores necesarios a CUDA.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    aligned_dataset = []\n",
    "\n",
    "    print(\"Procesando el dataset en GPU (si está disponible)...\")\n",
    "\n",
    "    for example in dataset:\n",
    "        # Convertir listas a tensores y mover a GPU\n",
    "        input_ids_tensor = torch.tensor(example[\"input_ids\"], dtype=torch.long).to(device)\n",
    "        labels_tensor = torch.tensor(example[\"labels\"], dtype=torch.float32).to(device)\n",
    "\n",
    "        # Ajustar `labels` para que tengan exactamente max_label_length\n",
    "        if labels_tensor.shape[0] > max_label_length:\n",
    "            aligned_labels = labels_tensor[:max_label_length]\n",
    "        else:\n",
    "            aligned_labels = F.pad(labels_tensor, (0, max_label_length - labels_tensor.shape[0]))\n",
    "\n",
    "        # Ajustar `input_ids`\n",
    "        padded_input_ids = F.pad(input_ids_tensor, (0, max_label_length - len(input_ids_tensor)), value=pad_token_id)\n",
    "\n",
    "        # Crear un nuevo ejemplo alineado\n",
    "        aligned_example = {\n",
    "            \"input_ids\": padded_input_ids[:max_label_length],\n",
    "            \"attention_mask\": torch.ones_like(padded_input_ids[:max_label_length]),\n",
    "            \"labels\": aligned_labels\n",
    "        }\n",
    "        aligned_dataset.append({k: v.cpu() for k, v in aligned_example.items()})  # Pasar a CPU para liberar memoria\n",
    "\n",
    "    print(\"Preprocesamiento y alineamiento completados.\")\n",
    "    return aligned_dataset\n",
    "\n",
    "# Dividir el dataset en dos mitades\n",
    "if isinstance(small_dataset, Dataset):\n",
    "    small_dataset = [example for example in small_dataset if len(example[\"labels\"]) > 0]\n",
    "\n",
    "\n",
    "dataset_splits = split_dataset(small_dataset, num_splits=2)\n",
    "\n",
    "# Procesar la primera mitad\n",
    "print(\"Procesando la primera mitad del dataset...\")\n",
    "aligned_dataset_part1 = preprocess_and_align(dataset_splits[0], pad_token_id=0, max_label_length=500)\n",
    "\n",
    "# Entrenar con la primera mitad del dataset alineado\n",
    "print(f\"Tamaño del dataset alineado (parte 1): {len(aligned_dataset_part1)}\")\n",
    "\n",
    "# Procesar la segunda mitad (si es necesario más adelante)\n",
    "print(\"Procesando la segunda mitad del dataset (opcional)...\")\n",
    "aligned_dataset_part2 = preprocess_and_align(dataset_splits[1], pad_token_id=0, max_label_length=500)\n",
    "\n",
    "# Validar algunos ejemplos de la primera mitad\n",
    "print(\"Validando ejemplos alineados de la primera mitad:\")\n",
    "for idx, example in enumerate(aligned_dataset_part1[:5]):  # Muestra los primeros 5 ejemplos\n",
    "    print(f\"Ejemplo {idx}:\")\n",
    "    print(f\"input_ids shape: {example['input_ids'].shape}\")\n",
    "    print(f\"labels shape: {example['labels'].shape}\")\n",
    "    print(f\"attention_mask shape: {example['attention_mask'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa940d2076c4412b9441b57c5013b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 26\u001b[0m\n\u001b[0;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     19\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     20\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m     21\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39maligned_dataset_part1,  \u001b[38;5;66;03m# Solo el conjunto de entrenamiento\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Ya alineaste los datos, así que no necesitas data_collator\u001b[39;00m\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2345\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2342\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 2345\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_num_input_tokens_seen\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\data_loader.py:559\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 559\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[0;32m    561\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\operations.py:184\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m--> 184\u001b[0m         \u001b[43m{\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\operations.py:185\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[0;32m    184\u001b[0m         {\n\u001b[1;32m--> 185\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    187\u001b[0m         }\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\operations.py:156\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    154\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "# Configurar argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_total_limit=2,  # Limita el número de checkpoints guardados\n",
    ")\n",
    "\n",
    "# Configurar el Trainer sin eval_dataset ni compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=aligned_dataset_part1,  # Solo el conjunto de entrenamiento\n",
    "    data_collator=None,  # Ya alineaste los datos, así que no necesitas data_collator\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
