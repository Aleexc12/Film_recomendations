{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvporcupine\n",
    "import sounddevice as sd\n",
    "\n",
    "# Configuración de Porcupine con access_key\n",
    "porcupine = pvporcupine.create(\n",
    "    access_key=\"qEcRoI9pyPji4cEIXkMNz4+G34KlNQMO5mouLLJzGsvb5PF5fuaKlg==\",  # Reemplaza con tu clave de acceso\n",
    "    keyword_paths=[\"resources/wakeword.ppn\"],\n",
    "    model_path=\"resources/porcupine_params_es.pv\" \n",
    ")\n",
    "\n",
    "def wake_word_detected():\n",
    "    print(\"Wake word detectado. Escuchando tu comando...\")\n",
    "import numpy as np\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if len(indata) != porcupine.frame_length:\n",
    "        print(f\"Ajustando frame length. Original: {len(indata)}, esperado: {porcupine.frame_length}\")\n",
    "        # Interpolamos para ajustar el tamaño del frame\n",
    "        factor = porcupine.frame_length / len(indata)\n",
    "        indata = np.interp(\n",
    "            np.arange(0, len(indata) * factor) / factor,  # Nuevas posiciones\n",
    "            np.arange(len(indata)),  # Posiciones originales\n",
    "            indata[:, 0]  # Solo el primer canal\n",
    "        ).astype(\"int16\")\n",
    "\n",
    "    pcm = indata  # Ya está ajustado\n",
    "    keyword_index = porcupine.process(pcm)\n",
    "    if keyword_index >= 0:\n",
    "        wake_word_detected()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el modelo de Whisper\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    print(\"Escuchando comando...\")\n",
    "    duration = 5  # Duración en segundos\n",
    "    audio = sd.rec(int(duration * 16000), samplerate=16000, channels=1, dtype='float32')\n",
    "    sd.wait()  # Esperar a que termine la grabación\n",
    "    \n",
    "    # Guardar el audio en un archivo temporal\n",
    "    np.save(\"audio_temp.npy\", audio)\n",
    "    print(\"Transcribiendo...\")\n",
    "    \n",
    "    # Usar Whisper para convertir audio a texto\n",
    "    result = model.transcribe(\"audio_temp.npy\", language=\"es\")\n",
    "    return result['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_command(command):\n",
    "    print(f\"Comando recibido: {command}\")\n",
    "    genre = None\n",
    "    runtime = None\n",
    "\n",
    "    # Ejemplo de procesamiento básico\n",
    "    if \"amor\" in command:\n",
    "        genre = \"romance\"\n",
    "    if \"menos de 1:30\" in command or \"corta\" in command:\n",
    "        runtime = 90\n",
    "\n",
    "    return {\n",
    "        \"genre\": genre,\n",
    "        \"runtime\": runtime\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'adult': False, 'backdrop_path': '/8mjYwWT50GkRrrRdyHzJorfEfcl.jpg', 'genre_ids': [28, 12, 18], 'id': 558449, 'original_language': 'en', 'original_title': 'Gladiator II', 'overview': 'Years after witnessing the death of the revered hero Maximus at the hands of his uncle, Lucius is forced to enter the Colosseum after his home is conquered by the tyrannical Emperors who now lead Rome with an iron fist. With rage in his heart and the future of the Empire at stake, Lucius must look to his past to find strength and honor to return the glory of Rome to its people.', 'popularity': 2557.256, 'poster_path': '/2cxhvwyEwRlysAmRH4iodkvo0z5.jpg', 'release_date': '2024-11-13', 'title': 'Gladiator II', 'video': False, 'vote_average': 6.836, 'vote_count': 341}, {'adult': False, 'backdrop_path': '/18TSJF1WLA4CkymvVUcKDBwUJ9F.jpg', 'genre_ids': [27, 53, 9648], 'id': 1034541, 'original_language': 'en', 'original_title': 'Terrifier 3', 'overview': \"Five years after surviving Art the Clown's Halloween massacre, Sienna and Jonathan are still struggling to rebuild their shattered lives. As the holiday season approaches, they try to embrace the Christmas spirit and leave the horrors of the past behind. But just when they think they're safe, Art returns, determined to turn their holiday cheer into a new nightmare. The festive season quickly unravels as Art unleashes his twisted brand of terror, proving that no holiday is safe.\", 'popularity': 3158.896, 'poster_path': '/l1175hgL5DoXnqeZQCcU3eZIdhX.jpg', 'release_date': '2024-10-09', 'title': 'Terrifier 3', 'video': False, 'vote_average': 6.911, 'vote_count': 994}, {'adult': False, 'backdrop_path': '/90ez6ArvpO8bvpyIngBuwXOqJm5.jpg', 'genre_ids': [35, 18, 10749], 'id': 19404, 'original_language': 'hi', 'original_title': 'दिलवाले दुल्हनिया ले जायेंगे', 'overview': 'Raj is a rich, carefree, happy-go-lucky second generation NRI. Simran is the daughter of Chaudhary Baldev Singh, who in spite of being an NRI is very strict about adherence to Indian values. Simran has left for India to be married to her childhood fiancé. Raj leaves for India with a mission at his hands, to claim his lady love under the noses of her whole family. Thus begins a saga.', 'popularity': 35.89, 'poster_path': '/lfRkUr7DYdHldAqi3PwdQGBRBPM.jpg', 'release_date': '1995-10-20', 'title': 'Dilwale Dulhania Le Jayenge', 'video': False, 'vote_average': 8.5, 'vote_count': 4437}, {'adult': False, 'backdrop_path': '/Adrip2Jqzw56KeuV2nAxucKMNXA.jpg', 'genre_ids': [37], 'id': 429, 'original_language': 'it', 'original_title': 'Il buono, il brutto, il cattivo', 'overview': 'While the Civil War rages on between the Union and the Confederacy, three men – a quiet loner, a ruthless hitman, and a Mexican bandit – comb the American Southwest in search of a strongbox containing $200,000 in stolen gold.', 'popularity': 91.649, 'poster_path': '/bX2xnavhMYjWDoZp1VM6VnU1xwe.jpg', 'release_date': '1966-12-22', 'title': 'The Good, the Bad and the Ugly', 'video': False, 'vote_average': 8.463, 'vote_count': 8597}, {'adult': False, 'backdrop_path': '/sJNNMCc6B7KZIY3LH3JMYJJNH5j.jpg', 'genre_ids': [28, 18], 'id': 346, 'original_language': 'ja', 'original_title': '七人の侍', 'overview': \"A samurai answers a village's request for protection after he falls on hard times. The town needs protection from bandits, so the samurai gathers six others to help him teach the people how to defend themselves, and the villagers provide the soldiers with food.\", 'popularity': 53.872, 'poster_path': '/iAq0sq42vKTLneVGqHn1D4GzgrM.jpg', 'release_date': '1954-04-26', 'title': 'Seven Samurai', 'video': False, 'vote_average': 8.463, 'vote_count': 3667}, {'adult': False, 'backdrop_path': '/7lyq8hK0MhPHpUXdnqbFvZYSfkk.jpg', 'genre_ids': [18, 10749], 'id': 11216, 'original_language': 'it', 'original_title': 'Nuovo Cinema Paradiso', 'overview': \"A filmmaker recalls his childhood, when he fell in love with the movies at his village's theater and formed a deep friendship with the theater's projectionist.\", 'popularity': 36.62, 'poster_path': '/gCI2AeMV4IHSewhJkzsur5MEp6R.jpg', 'release_date': '1988-11-17', 'title': 'Cinema Paradiso', 'video': False, 'vote_average': 8.4, 'vote_count': 4361}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL del servidor Flask\n",
    "BASE_URL = \"http://127.0.0.1:5000\"\n",
    "\n",
    "# Obtener la lista de seguimiento (después de autenticarse)\n",
    "response = requests.get(f\"{BASE_URL}/get_watchlist\")\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_wake_word():\n",
    "    def audio_callback(indata, frames, time, status):\n",
    "        if status:\n",
    "            print(f\"Estado del stream: {status}\")\n",
    "        \n",
    "        # Verifica si el tamaño del frame es correcto\n",
    "        if len(indata) == porcupine.frame_length:\n",
    "            pcm = indata[:, 0]  # Procesa solo el canal mono\n",
    "            keyword_index = porcupine.process(pcm)\n",
    "            if keyword_index >= 0:\n",
    "                wake_word_detected()\n",
    "        else:\n",
    "            print(f\"Frame length inválido: esperado {porcupine.frame_length}, recibido {len(indata)}\")\n",
    "\n",
    "    # Configurar el flujo de audio con blocksize\n",
    "    with sd.InputStream(\n",
    "        callback=audio_callback,\n",
    "        channels=1,  # Mono\n",
    "        samplerate=porcupine.sample_rate,  # 16000 Hz\n",
    "        blocksize=porcupine.frame_length,  # Asegurar el tamaño del bloque\n",
    "        dtype=\"int16\",  # Formato esperado por Porcupine\n",
    "    ):\n",
    "        print(\"Escuchando activación...\")\n",
    "        while True:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando el sistema de detección de wake word...\n",
      "Escuchando activación...\n",
      "Wake word detectado. Preparando para escuchar el comando...\n",
      "Grabando audio por 5 segundos...\n",
      "Grabación completada.\n",
      "Audio guardado en c:\\Users\\alexc\\OneDrive - Universidad Politécnica de Madrid\\Escritorio\\CDIA\\Proyectos\\Film_recomendations\\temp_audio.wav\n",
      "Sistema de detección finalizado.\n"
     ]
    }
   ],
   "source": [
    "import pvporcupine\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "\n",
    "DEVICE_INDEX = 5  # Ajustar al índice correcto según tu micrófono\n",
    "running = True  # Bandera para controlar el bucle principal\n",
    "\n",
    "# Configuración de Porcupine\n",
    "try:\n",
    "    porcupine = pvporcupine.create(\n",
    "        access_key=\"qEcRoI9pyPji4cEIXkMNz4+G34KlNQMO5mouLLJzGsvb5PF5fuaKlg==\",\n",
    "        keyword_paths=[\"resources/wakeword.ppn\"],\n",
    "        model_path=\"resources/porcupine_params_es.pv\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error al inicializar Porcupine: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "def wake_word_detected():\n",
    "    global running\n",
    "    print(\"Wake word detectado. Preparando para escuchar el comando...\")\n",
    "    grabar_comando()\n",
    "    running = False  # Detener el bucle principal\n",
    "\n",
    "def grabar_comando():\n",
    "    print(\"Grabando audio por 5 segundos...\")\n",
    "    try:\n",
    "        duration = 5\n",
    "        audio = sd.rec(int(duration * 16000), samplerate=16000, channels=1, dtype='int16', device=DEVICE_INDEX)\n",
    "        sd.wait()\n",
    "        print(\"Grabación completada.\")\n",
    "        \n",
    "        # Guardar el archivo en formato estándar para Whisper\n",
    "        temp_audio_path = \"temp_audio.wav\"\n",
    "        write(temp_audio_path, 16000, audio)\n",
    "        print(f\"Audio guardado en {os.path.abspath(temp_audio_path)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al grabar audio: {e}\")\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(f\"Estado del stream: {status}\")\n",
    "    try:\n",
    "        pcm = indata[:, 0]\n",
    "        keyword_index = porcupine.process(pcm)\n",
    "        if keyword_index >= 0:\n",
    "            wake_word_detected()\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el callback: {e}\")\n",
    "\n",
    "def detect_wake_word():\n",
    "    global running\n",
    "    print(\"Iniciando el sistema de detección de wake word...\")\n",
    "    try:\n",
    "        with sd.InputStream(\n",
    "            device=DEVICE_INDEX,\n",
    "            callback=audio_callback,\n",
    "            channels=1,\n",
    "            samplerate=porcupine.sample_rate,\n",
    "            blocksize=porcupine.frame_length,\n",
    "            dtype=\"int16\",\n",
    "            latency=\"low\"\n",
    "        ) as stream:\n",
    "            print(\"Escuchando activación...\")\n",
    "            while running:\n",
    "                time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterrupción detectada. Finalizando el programa...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el sistema de detección: {e}\")\n",
    "    finally:\n",
    "        porcupine.delete()\n",
    "        print(\"Sistema de detección finalizado.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    detect_wake_word()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo de Whisper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo encontrado: c:\\Users\\alexc\\OneDrive - Universidad Politécnica de Madrid\\Escritorio\\CDIA\\Proyectos\\Film_recomendations\\temp_audio.wav\n",
      "Procesando transcripción...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción: \n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\ffmpeg\\bin\"\n",
    "# Cargar el modelo de Whisper\n",
    "print(\"Cargando modelo de Whisper...\")\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "def transcribe_audio(filename):\n",
    "    \"\"\"Transcribir audio usando Whisper\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Archivo encontrado: {os.path.abspath(filename)}\")\n",
    "        print(\"Procesando transcripción...\")\n",
    "        try:\n",
    "            # Asegúrate de que el archivo está accesible y tiene el formato correcto\n",
    "            result = model.transcribe(filename, language=\"es\")\n",
    "            print(f\"Transcripción: {result['text']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al transcribir el audio: {e}\")\n",
    "    else:\n",
    "        print(f\"Error: El archivo {filename} no existe o no es accesible.\")\n",
    "\n",
    "# Ruta del archivo generado en la parte anterior\n",
    "wav_filename = \"temp_audio.wav\"\n",
    "transcribe_audio(wav_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Películas en la Watchlist:\n",
      "- Gladiator II (2024-11-13): Years after witnessing the death of the revered hero Maximus at the hands of his uncle, Lucius is forced to enter the Colosseum after his home is conquered by the tyrannical Emperors who now lead Rome with an iron fist. With rage in his heart and the future of the Empire at stake, Lucius must look to his past to find strength and honor to return the glory of Rome to its people.\n",
      "- Terrifier 3 (2024-10-09): Five years after surviving Art the Clown's Halloween massacre, Sienna and Jonathan are still struggling to rebuild their shattered lives. As the holiday season approaches, they try to embrace the Christmas spirit and leave the horrors of the past behind. But just when they think they're safe, Art returns, determined to turn their holiday cheer into a new nightmare. The festive season quickly unravels as Art unleashes his twisted brand of terror, proving that no holiday is safe.\n",
      "- Dilwale Dulhania Le Jayenge (1995-10-20): Raj is a rich, carefree, happy-go-lucky second generation NRI. Simran is the daughter of Chaudhary Baldev Singh, who in spite of being an NRI is very strict about adherence to Indian values. Simran has left for India to be married to her childhood fiancé. Raj leaves for India with a mission at his hands, to claim his lady love under the noses of her whole family. Thus begins a saga.\n",
      "- The Good, the Bad and the Ugly (1966-12-22): While the Civil War rages on between the Union and the Confederacy, three men – a quiet loner, a ruthless hitman, and a Mexican bandit – comb the American Southwest in search of a strongbox containing $200,000 in stolen gold.\n",
      "- Seven Samurai (1954-04-26): A samurai answers a village's request for protection after he falls on hard times. The town needs protection from bandits, so the samurai gathers six others to help him teach the people how to defend themselves, and the villagers provide the soldiers with food.\n",
      "- Cinema Paradiso (1988-11-17): A filmmaker recalls his childhood, when he fell in love with the movies at his village's theater and formed a deep friendship with the theater's projectionist.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL del servidor Flask\n",
    "BASE_URL = \"http://127.0.0.1:5000\"\n",
    "\n",
    "# Endpoint para obtener la watchlist\n",
    "endpoint = \"/get_watchlist\"\n",
    "\n",
    "# Hacer la solicitud GET\n",
    "response = requests.get(f\"{BASE_URL}{endpoint}\")\n",
    "\n",
    "# Verificar el resultado\n",
    "if response.status_code == 200:\n",
    "    watchlist = response.json()\n",
    "    print(\"Películas en la Watchlist:\")\n",
    "    for movie in watchlist[\"results\"]:\n",
    "        print(f\"- {movie['title']} ({movie['release_date']}): {movie['overview']}\")\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_genre(transcription):\n",
    "    \"\"\"\n",
    "    Clasifica todos los géneros mencionados en la transcripción a sus IDs correspondientes en TMDb.\n",
    "    \"\"\"\n",
    "    genre_dict = {\n",
    "        \"acción\": 28,\n",
    "        \"aventura\": 12,\n",
    "        \"animación\": 16,\n",
    "        \"comedia\": 35,\n",
    "        \"crimen\": 80,\n",
    "        \"documental\": 99,\n",
    "        \"drama\": 18,\n",
    "        \"familia\": 10751,\n",
    "        \"fantasía\": 14,\n",
    "        \"historia\": 36,\n",
    "        \"terror\": 27,\n",
    "        \"música\": 10402,\n",
    "        \"misterio\": 9648,\n",
    "        \"romance\": 10749,\n",
    "        \"ciencia ficción\": 878,\n",
    "        \"película de tv\": 10770,\n",
    "        \"thriller\": 53,\n",
    "        \"bélico\": 10752,\n",
    "        \"western\": 37\n",
    "    }\n",
    "\n",
    "    transcription = transcription.lower()\n",
    "\n",
    "    # Buscar todos los géneros mencionados\n",
    "    genres_found = [\n",
    "        genre_id for genre_name, genre_id in genre_dict.items()\n",
    "        if genre_name in transcription\n",
    "    ]\n",
    "\n",
    "    return genres_found if genres_found else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Asegúrate de tener este modelo\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "def process_transcription_to_params(transcription):\n",
    "    \"\"\"\n",
    "    Transforma el texto de la transcripción en parámetros para la solicitud.\n",
    "    \"\"\"\n",
    "    transcription = transcription.lower()\n",
    "    \n",
    "    # Inicializar parámetros\n",
    "    params = {\n",
    "        \"vote_count\": None,\n",
    "        \"vote_average\": None,\n",
    "        \"after_year\": None,\n",
    "        \"before_year\": None,\n",
    "        \"adult\": None,\n",
    "        \"language\": None,\n",
    "        \"genre\": None\n",
    "    }\n",
    "    \n",
    "    # Clasificar el género\n",
    "    params[\"genre\"] = classify_genre(transcription)\n",
    "    \n",
    "    # Identificar si es para adultos o familiar\n",
    "    if \"adulto\" in transcription:\n",
    "        params[\"adult\"] = True\n",
    "    elif \"familiar\" in transcription:\n",
    "        params[\"adult\"] = False\n",
    "    \n",
    "    # Procesar números (años y puntuaciones)\n",
    "    nlp_doc = nlp(transcription)\n",
    "    for token in nlp_doc:\n",
    "        if token.like_num:\n",
    "            number = float(token.text)\n",
    "            \n",
    "            # Identificar votación promedio\n",
    "            if any(keyword in transcription for keyword in [\"más de\", \"mayor a\", \"superior a\", \"por encima de\"]):\n",
    "                params[\"vote_average\"] = number\n",
    "            \n",
    "            # Identificar años\n",
    "            if len(token.text) == 4:  # Probable año\n",
    "                if \"antes de\" in transcription:\n",
    "                    params[\"before_year\"] = int(number)\n",
    "                elif \"después de\" in transcription or \"posterior a\" in transcription:\n",
    "                    params[\"after_year\"] = int(number)\n",
    "\n",
    "    # Identificar idioma\n",
    "    if \"español\" in transcription:\n",
    "        params[\"language\"] = \"es\"\n",
    "    elif \"inglés\" in transcription:\n",
    "        params[\"language\"] = \"en\"\n",
    "    elif \"francés\" in transcription:\n",
    "        params[\"language\"] = \"fr\"\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vote_count': None, 'vote_average': 5.0, 'after_year': 2020, 'before_year': None, 'adult': None, 'language': None, 'genre': [28, 878]}\n"
     ]
    }
   ],
   "source": [
    "# Texto de entrada\n",
    "transcription = \"Quiero una película de ciencia ficción o acción que sea de después de 2020 y con una nota superior a 5.\"\n",
    "\n",
    "# Transformar el texto en parámetros\n",
    "params = process_transcription_to_params(transcription)\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'adult': False, 'backdrop_path': '/8mjYwWT50GkRrrRdyHzJorfEfcl.jpg', 'genre_ids': [28, 12, 18], 'id': 558449, 'original_language': 'en', 'original_title': 'Gladiator II', 'overview': 'Years after witnessing the death of the revered hero Maximus at the hands of his uncle, Lucius is forced to enter the Colosseum after his home is conquered by the tyrannical Emperors who now lead Rome with an iron fist. With rage in his heart and the future of the Empire at stake, Lucius must look to his past to find strength and honor to return the glory of Rome to its people.', 'popularity': 2557.256, 'poster_path': '/2cxhvwyEwRlysAmRH4iodkvo0z5.jpg', 'release_date': '2024-11-13', 'title': 'Gladiator II', 'video': False, 'vote_average': 6.836, 'vote_count': 341}, {'adult': False, 'backdrop_path': '/18TSJF1WLA4CkymvVUcKDBwUJ9F.jpg', 'genre_ids': [27, 53, 9648], 'id': 1034541, 'original_language': 'en', 'original_title': 'Terrifier 3', 'overview': \"Five years after surviving Art the Clown's Halloween massacre, Sienna and Jonathan are still struggling to rebuild their shattered lives. As the holiday season approaches, they try to embrace the Christmas spirit and leave the horrors of the past behind. But just when they think they're safe, Art returns, determined to turn their holiday cheer into a new nightmare. The festive season quickly unravels as Art unleashes his twisted brand of terror, proving that no holiday is safe.\", 'popularity': 3158.896, 'poster_path': '/l1175hgL5DoXnqeZQCcU3eZIdhX.jpg', 'release_date': '2024-10-09', 'title': 'Terrifier 3', 'video': False, 'vote_average': 6.911, 'vote_count': 994}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "params = params\n",
    "BASE_URL = \"http://127.0.0.1:5000\"\n",
    "response = requests.get(f\"{BASE_URL}/get_watchlist\", params=params)\n",
    "if response.status_code == 200:\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: comtypes in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyttsx3) (1.4.8)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\alexc\\appdata\\roaming\\python\\python311\\site-packages (from pyttsx3) (306)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alexc\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\alexc\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "inputs = processor(text=\"Hola, mi perro es mono.\", return_tensors=\"pt\")\n",
    "\n",
    "# load xvector containing speaker's voice characteristics from a dataset\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
    "\n",
    "sf.write(\"speech.wav\", speech.numpy(), samplerate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta actual: c:\\Proyectos\\Film_recomendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbef86b2a9e414283c0d1a2e99f0313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 230467\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import os\n",
    "# Obtener la ruta actual\n",
    "current_path = os.getcwd()\n",
    "print(f\"Ruta actual: {current_path}\")\n",
    "\n",
    "# Especificar el nombre del directorio para guardar/cargar el dataset\n",
    "dataset_path = os.path.join(current_path, \"tokenized_datasets\")\n",
    "\n",
    "# Cargar el dataset tokenizado\n",
    "tokenized_datasets = load_from_disk(dataset_path)\n",
    "print(tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Toma solo una fracción del dataset\n",
    "reduction_factor = 0.005  # Usa solo el 10% del dataset\n",
    "small_dataset = tokenized_datasets.select(range(int(len(tokenized_datasets) * reduction_factor)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando la primera mitad del dataset...\n",
      "Procesando el dataset en GPU (si está disponible)...\n",
      "Preprocesamiento y alineamiento completados.\n",
      "Tamaño del dataset alineado (parte 1): 576\n",
      "Validando ejemplos alineados de la primera mitad:\n",
      "Ejemplo 0:\n",
      "input_ids shape: torch.Size([500])\n",
      "labels shape: torch.Size([500, 80])\n",
      "attention_mask shape: torch.Size([500])\n",
      "Ejemplo 1:\n",
      "input_ids shape: torch.Size([500])\n",
      "labels shape: torch.Size([500, 80])\n",
      "attention_mask shape: torch.Size([500])\n",
      "Ejemplo 2:\n",
      "input_ids shape: torch.Size([500])\n",
      "labels shape: torch.Size([500, 80])\n",
      "attention_mask shape: torch.Size([500])\n",
      "Ejemplo 3:\n",
      "input_ids shape: torch.Size([500])\n",
      "labels shape: torch.Size([500, 80])\n",
      "attention_mask shape: torch.Size([500])\n",
      "Ejemplo 4:\n",
      "input_ids shape: torch.Size([500])\n",
      "labels shape: torch.Size([500, 80])\n",
      "attention_mask shape: torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def split_dataset(dataset, num_splits=2):\n",
    "    \"\"\"\n",
    "    Divide un dataset en partes iguales.\n",
    "    \"\"\"\n",
    "    split_size = len(dataset) // num_splits\n",
    "    splits = [dataset[i * split_size: (i + 1) * split_size] for i in range(num_splits)]\n",
    "    if len(dataset) % num_splits != 0:  # Si queda algo al final, lo añadimos a la última parte\n",
    "        splits[-1].extend(dataset[num_splits * split_size:])\n",
    "    return splits\n",
    "\n",
    "def preprocess_and_align(dataset, pad_token_id=0, max_label_length=500):\n",
    "    \"\"\"\n",
    "    Preprocesa y alinea un dataset completo moviendo los tensores necesarios a CUDA.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    aligned_dataset = []\n",
    "\n",
    "    print(\"Procesando el dataset en GPU (si está disponible)...\")\n",
    "\n",
    "    for example in dataset:\n",
    "        # Convertir listas a tensores y mover a GPU\n",
    "        input_ids_tensor = torch.tensor(example[\"input_ids\"], dtype=torch.long).to(device)\n",
    "        labels_tensor = torch.tensor(example[\"labels\"], dtype=torch.float32).to(device)\n",
    "\n",
    "        # Ajustar `labels` para que tengan exactamente max_label_length\n",
    "        if labels_tensor.shape[0] > max_label_length:\n",
    "            aligned_labels = labels_tensor[:max_label_length]\n",
    "        else:\n",
    "            aligned_labels = F.pad(labels_tensor, (0, max_label_length - labels_tensor.shape[0]))\n",
    "\n",
    "        # Ajustar `input_ids`\n",
    "        padded_input_ids = F.pad(input_ids_tensor, (0, max_label_length - len(input_ids_tensor)), value=pad_token_id)\n",
    "\n",
    "        # Crear un nuevo ejemplo alineado\n",
    "        aligned_example = {\n",
    "            \"input_ids\": padded_input_ids[:max_label_length],\n",
    "            \"attention_mask\": torch.ones_like(padded_input_ids[:max_label_length]),\n",
    "            \"labels\": aligned_labels\n",
    "        }\n",
    "        aligned_dataset.append({k: v.cpu() for k, v in aligned_example.items()})  # Pasar a CPU para liberar memoria\n",
    "\n",
    "    print(\"Preprocesamiento y alineamiento completados.\")\n",
    "    return aligned_dataset\n",
    "\n",
    "# Dividir el dataset en dos mitades\n",
    "if isinstance(small_dataset, Dataset):\n",
    "    small_dataset = [example for example in small_dataset if len(example[\"labels\"]) > 0]\n",
    "\n",
    "\n",
    "dataset_splits = split_dataset(small_dataset, num_splits=2)\n",
    "\n",
    "# Procesar la primera mitad\n",
    "print(\"Procesando la primera mitad del dataset...\")\n",
    "aligned_dataset_part1 = preprocess_and_align(dataset_splits[0], pad_token_id=0, max_label_length=500)\n",
    "\n",
    "# Entrenar con la primera mitad del dataset alineado\n",
    "print(f\"Tamaño del dataset alineado (parte 1): {len(aligned_dataset_part1)}\")\n",
    "\n",
    "# Procesar la segunda mitad (si es necesario más adelante)\n",
    "# print(\"Procesando la segunda mitad del dataset (opcional)...\")\n",
    "# aligned_dataset_part2 = preprocess_and_align(dataset_splits[1], pad_token_id=0, max_label_length=500)\n",
    "\n",
    "# Validar algunos ejemplos de la primera mitad\n",
    "print(\"Validando ejemplos alineados de la primera mitad:\")\n",
    "for idx, example in enumerate(aligned_dataset_part1[:5]):  # Muestra los primeros 5 ejemplos\n",
    "    print(f\"Ejemplo {idx}:\")\n",
    "    print(f\"input_ids shape: {example['input_ids'].shape}\")\n",
    "    print(f\"labels shape: {example['labels'].shape}\")\n",
    "    print(f\"attention_mask shape: {example['attention_mask'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   | 338944 B   |  95616 KiB |  95616 KiB |\n",
      "|       from large pool |      0 B   |      0 B   |      0 KiB |      0 KiB |\n",
      "|       from small pool |      0 B   | 338944 B   |  95616 KiB |  95616 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   | 338944 B   |  95616 KiB |  95616 KiB |\n",
      "|       from large pool |      0 B   |      0 B   |      0 KiB |      0 KiB |\n",
      "|       from small pool |      0 B   | 338944 B   |  95616 KiB |  95616 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   | 337536 B   |  95184 KiB |  95184 KiB |\n",
      "|       from large pool |      0 B   |      0 B   |      0 KiB |      0 KiB |\n",
      "|       from small pool |      0 B   | 337536 B   |  95184 KiB |  95184 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |   2048 KiB |   2048 KiB |   2048 KiB |\n",
      "|       from large pool |      0 B   |      0 KiB |      0 KiB |      0 KiB |\n",
      "|       from small pool |      0 B   |   2048 KiB |   2048 KiB |   2048 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |   2047 KiB |  97506 KiB |  97506 KiB |\n",
      "|       from large pool |      0 B   |      0 KiB |      0 KiB |      0 KiB |\n",
      "|       from small pool |      0 B   |   2047 KiB |  97506 KiB |  97506 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       7    |    2304    |    2304    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       7    |    2304    |    2304    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       7    |    2304    |    2304    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       7    |    2304    |    2304    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       1    |       1    |       1    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       1    |       1    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       3    |     865    |     865    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       3    |     865    |     865    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()  # Limpia la memoria no utilizada\n",
    "print(torch.cuda.memory_summary())  # Verifica el uso actual de memoria\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90282c0866e24bc799e87b0b441aaf27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 1876}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
      "{'train_runtime': 196.9177, 'train_samples_per_second': 8.775, 'train_steps_per_second': 4.388, 'train_loss': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=864, training_loss=0.0, metrics={'train_runtime': 196.9177, 'train_samples_per_second': 8.775, 'train_steps_per_second': 4.388, 'total_flos': 748305195264000.0, 'train_loss': 0.0, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "# Configurar argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  # Habilitar precisión mixta\n",
    ")\n",
    "\n",
    " \n",
    "# Configurar el Trainer sin eval_dataset ni compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=aligned_dataset_part1,  # Solo el conjunto de entrenamiento\n",
    "    data_collator=None,  # Ya alineaste los datos, así que no necesitas data_collator\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import Dataset\n",
    "import torchaudio\n",
    "\n",
    "# Cargar el modelo y el procesador desde el checkpoint\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")  # Último checkpoint\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"./results/checkpoint-864\")\n",
    "hifi_gan = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")  # Vocoder para mejorar el audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio generado y guardado en 'speech.wav'\n"
     ]
    }
   ],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import soundfile as sf\n",
    "\n",
    "# Cargar el procesador, modelo y vocoder\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"./results/checkpoint-864\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "# Texto de prueba\n",
    "inputs = processor(text=\"Hola, mi perro es mono.\", return_tensors=\"pt\")\n",
    "\n",
    "# Cargar embeddings del hablante\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "# Generar espectrograma con el modelo\n",
    "with torch.no_grad():\n",
    "    speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings=speaker_embeddings, vocoder=vocoder)\n",
    "\n",
    "# Guardar el archivo de audio\n",
    "sf.write(\"speech.wav\", speech.numpy(), samplerate=16000)  # 16kHz es la tasa de muestreo estándar\n",
    "print(\"Audio generado y guardado en 'speech.wav'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "    num_rows: 230467\n",
      "})\n",
      "{'client_id': '34719bb7c7344da7733b85c9d7215d24326093f1a2cd3a445bdc6dfe9ec4a8c9fe9729a73f6c29764545276bff81ffa65d3944f6da7a3ee3c06d0eb124fac797', 'path': 'C:\\\\Users\\\\alexc\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\2b79cc6219206153d43fce3a34af5d3200bd34fe6f7778eb294ec55a3a7d7854\\\\es_train_0/common_voice_es_18338585.mp3', 'audio': {'path': 'C:\\\\Users\\\\alexc\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\2b79cc6219206153d43fce3a34af5d3200bd34fe6f7778eb294ec55a3a7d7854\\\\es_train_0/common_voice_es_18338585.mp3', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "       -3.25855126e-06, -3.52389725e-06, -3.05285812e-06]), 'sampling_rate': 48000}, 'sentence': '¿ Qué tal a tres de cinco ?', 'up_votes': 2, 'down_votes': 1, 'age': '', 'gender': '', 'accent': '', 'locale': 'es', 'segment': ''}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Cargar el conjunto de datos de Common Voice para el idioma español\n",
    "dataset = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"es\", split=\"train\")\n",
    "\n",
    "# Inspeccionar el conjunto de datos\n",
    "print(dataset)\n",
    "print(dataset[0])  # Primer ejemplo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971804ef4aad41dca720ed835f449425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/230467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3444\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3443\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3444\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3445\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_writer.py:537\u001b[0m, in \u001b[0;36mArrowWriter.write\u001b[1;34m(self, example, key, writer_batch_size)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhkey_record \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 537\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_examples_on_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_writer.py:495\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m         batch_examples[col] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    492\u001b[0m             row[\u001b[38;5;241m0\u001b[39m][col]\u001b[38;5;241m.\u001b[39mto_pylist()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row[\u001b[38;5;241m0\u001b[39m][col], (pa\u001b[38;5;241m.\u001b[39mArray, pa\u001b[38;5;241m.\u001b[39mChunkedArray)) \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[38;5;241m0\u001b[39m][col]\n\u001b[0;32m    493\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples\n\u001b[0;32m    494\u001b[0m         ]\n\u001b[1;32m--> 495\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_writer.py:606\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[1;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[0;32m    605\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(pa\u001b[38;5;241m.\u001b[39marray(typed_sequence))\n\u001b[1;32m--> 606\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m \u001b[43mtyped_sequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inferred_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_writer.py:168\u001b[0m, in \u001b[0;36mTypedSequence.get_inferred_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type \u001b[38;5;241m=\u001b[39m generate_from_arrow_type(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\array.pxi:250\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\array.pxi:114\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_writer.py:243\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# We use cast_array_to_feature to support casting to custom types like Audio and Image\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# Also, when trying type \"string\", we don't want to convert integers or floats to \"string\".\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m# We only do it if trying_type is False - since this is what the user asks for.\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcast_array_to_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_primitive_to_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrying_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_decimal_to_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrying_type\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\table.py:1797\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[1;34m(array, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\table.py:1995\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[1;34m(array, feature, allow_primitive_to_str, allow_decimal_to_str)\u001b[0m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(feature, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast_storage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1995\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1997\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_struct(array\u001b[38;5;241m.\u001b[39mtype):\n\u001b[0;32m   1998\u001b[0m     \u001b[38;5;66;03m# feature must be a dict or Sequence(subfeatures_dict)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\features\\audio.py:234\u001b[0m, in \u001b[0;36mAudio.cast_storage\u001b[1;34m(self, storage)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_struct(storage\u001b[38;5;241m.\u001b[39mtype) \u001b[38;5;129;01mand\u001b[39;00m storage\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mget_all_field_indices(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 234\u001b[0m     storage \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39marray([Audio()\u001b[38;5;241m.\u001b[39mencode_example(x) \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pylist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_struct(storage\u001b[38;5;241m.\u001b[39mtype):\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\array.pxi:1656\u001b[0m, in \u001b[0;36mpyarrow.lib.Array.to_pylist\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\scalar.pxi:794\u001b[0m, in \u001b[0;36mpyarrow.lib.StructScalar.as_py\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen _collections_abc>:788\u001b[0m, in \u001b[0;36mkeys\u001b[1;34m(self)\u001b[0m\n",
      "File \u001b[1;32m<frozen _collections_abc>:812\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, mapping)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Procesar el dataset\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m processed_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_audio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3055\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3050\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3051\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3052\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3053\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3054\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3056\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3493\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[0;32m   3492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3493\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tmp_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3495\u001b[0m         tmp_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_writer.py:636\u001b[0m, in \u001b[0;36mArrowWriter.finalize\u001b[1;34m(self, close_stream)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;66;03m# Re-intializing to empty list for next batch\u001b[39;00m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhkey_record \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 636\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_examples_on_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# If schema is known, infer features even if no examples were written\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema:\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_writer.py:495\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    491\u001b[0m         batch_examples[col] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    492\u001b[0m             row[\u001b[38;5;241m0\u001b[39m][col]\u001b[38;5;241m.\u001b[39mto_pylist()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row[\u001b[38;5;241m0\u001b[39m][col], (pa\u001b[38;5;241m.\u001b[39mArray, pa\u001b[38;5;241m.\u001b[39mChunkedArray)) \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[38;5;241m0\u001b[39m][col]\n\u001b[0;32m    493\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples\n\u001b[0;32m    494\u001b[0m         ]\n\u001b[1;32m--> 495\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_writer.py:605\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[1;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[0;32m    603\u001b[0m         col_try_type \u001b[38;5;241m=\u001b[39m try_features[col] \u001b[38;5;28;01mif\u001b[39;00m try_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m try_features \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    604\u001b[0m         typed_sequence \u001b[38;5;241m=\u001b[39m OptimizedTypedSequence(col_values, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mcol_type, try_type\u001b[38;5;241m=\u001b[39mcol_try_type, col\u001b[38;5;241m=\u001b[39mcol)\n\u001b[1;32m--> 605\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyped_sequence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    606\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m typed_sequence\u001b[38;5;241m.\u001b[39mget_inferred_type()\n\u001b[0;32m    607\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\array.pxi:250\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\array.pxi:114\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_writer.py:243\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# otherwise we can finally use the user's type\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;66;03m# We use cast_array_to_feature to support casting to custom types like Audio and Image\u001b[39;00m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# Also, when trying type \"string\", we don't want to convert integers or floats to \"string\".\u001b[39;00m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;66;03m# We only do it if trying_type is False - since this is what the user asks for.\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mcast_array_to_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_primitive_to_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrying_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_decimal_to_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrying_type\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;167;01mTypeError\u001b[39;00m,\n\u001b[0;32m    249\u001b[0m     pa\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    250\u001b[0m     pa\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    251\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# handle type errors and overflows\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;66;03m# Ignore ArrowNotImplementedError caused by trying type, otherwise re-raise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\table.py:1797\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[1;34m(array, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mchunked_array([func(chunk, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mchunks])\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\table.py:1995\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[1;34m(array, feature, allow_primitive_to_str, allow_decimal_to_str)\u001b[0m\n\u001b[0;32m   1993\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mstorage\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(feature, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast_storage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1995\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1997\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_struct(array\u001b[38;5;241m.\u001b[39mtype):\n\u001b[0;32m   1998\u001b[0m     \u001b[38;5;66;03m# feature must be a dict or Sequence(subfeatures_dict)\u001b[39;00m\n\u001b[0;32m   1999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature\u001b[38;5;241m.\u001b[39mfeature, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\features\\audio.py:234\u001b[0m, in \u001b[0;36mAudio.cast_storage\u001b[1;34m(self, storage)\u001b[0m\n\u001b[0;32m    232\u001b[0m     storage \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mStructArray\u001b[38;5;241m.\u001b[39mfrom_arrays([storage, path_array], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m], mask\u001b[38;5;241m=\u001b[39mstorage\u001b[38;5;241m.\u001b[39mis_null())\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_struct(storage\u001b[38;5;241m.\u001b[39mtype) \u001b[38;5;129;01mand\u001b[39;00m storage\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mget_all_field_indices(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 234\u001b[0m     storage \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39marray([Audio()\u001b[38;5;241m.\u001b[39mencode_example(x) \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pylist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_struct(storage\u001b[38;5;241m.\u001b[39mtype):\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m storage\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mget_field_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\array.pxi:1656\u001b[0m, in \u001b[0;36mpyarrow.lib.Array.to_pylist\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\scalar.pxi:794\u001b[0m, in \u001b[0;36mpyarrow.lib.StructScalar.as_py\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen _collections_abc>:788\u001b[0m, in \u001b[0;36mkeys\u001b[1;34m(self)\u001b[0m\n",
      "File \u001b[1;32m<frozen _collections_abc>:812\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, mapping)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "def process_audio(batch):\n",
    "    # Convertir el array de numpy a tensor con tipo float32\n",
    "    waveform = torch.tensor(batch[\"audio\"][\"array\"], dtype=torch.float32)\n",
    "    original_rate = batch[\"audio\"][\"sampling_rate\"]  # Obtener la frecuencia de muestreo original\n",
    "\n",
    "    # Resamplear a 16 kHz si es necesario\n",
    "    if original_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=original_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    batch[\"speech\"] = waveform\n",
    "    batch[\"sampling_rate\"] = 16000  # Actualizar la frecuencia de muestreo\n",
    "    return batch\n",
    "\n",
    "# Procesar el dataset\n",
    "processed_dataset = dataset.map(process_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "def resample_audio(batch):\n",
    "    waveform, sample_rate = torchaudio.load(batch[\"path\"])\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "    batch[\"speech\"] = resampler(waveform).squeeze(0)  # Mantén el audio como un tensor\n",
    "    batch[\"sampling_rate\"] = 16000  # Añadir la frecuencia de muestreo\n",
    "    return batch\n",
    "\n",
    "# Procesar los datos nuevamente\n",
    "resampled_dataset = dataset.map(resample_audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4289149601549e1b6b328674347f36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/179 shards):   0%|          | 0/230467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resampled_dataset.save_to_disk(\"./processed_common_voice\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta actual: c:\\Proyectos\\Film_recomendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e91fcd3bfd4859ab28b6fecc719b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'speech', 'sampling_rate'],\n",
      "    num_rows: 230467\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import os\n",
    "# Obtener la ruta actual\n",
    "current_path = os.getcwd()\n",
    "print(f\"Ruta actual: {current_path}\")\n",
    "\n",
    "# Especificar el nombre del directorio para guardar/cargar el dataset\n",
    "dataset_path = os.path.join(current_path, \"processed_common_voice\")\n",
    "\n",
    "# Cargar el dataset tokenizado\n",
    "resampled_dataset = load_from_disk(dataset_path)\n",
    "print(resampled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: ¿ Qué tal a tres de cinco ?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m example \u001b[38;5;241m=\u001b[39m resampled_dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexto: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForma de audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspeech\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Validar un ejemplo\n",
    "example = resampled_dataset[0]\n",
    "print(f\"Texto: {example['sentence']}\")\n",
    "print(f\"Forma de audio: {example['speech'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "\n",
    "def tokenize_text(batch):\n",
    "    inputs = processor(text=batch[\"sentence\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    batch[\"input_ids\"] = inputs.input_ids[0]\n",
    "    return batch\n",
    "\n",
    "tokenized_dataset = resampled_dataset.map(tokenize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d49de7c2d36481590384462aabd1e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/230467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_short\u001b[39m(batch):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1600\u001b[39m  \u001b[38;5;66;03m# Al menos 0.1 segundos de audio\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m filtered_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtokenized_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_short\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\fingerprint.py:442\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[0;32m    440\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3670\u001b[0m, in \u001b[0;36mDataset.filter\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m-> 3670\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_indices_from_mask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3677\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3678\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muint64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3692\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3694\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFilter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3697\u001b[0m new_dataset \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   3698\u001b[0m new_dataset\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3055\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3050\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3051\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3052\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3053\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3054\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3056\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3458\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3454\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   3455\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[0;32m   3456\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3458\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3462\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3465\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3466\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3467\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3320\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3319\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3320\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3322\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3323\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3324\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:6303\u001b[0m, in \u001b[0;36mget_indices_from_mask_function\u001b[1;34m(function, batched, with_indices, with_rank, input_columns, indices_mapping, *args, **fn_kwargs)\u001b[0m\n\u001b[0;32m   6301\u001b[0m num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch\u001b[38;5;241m.\u001b[39mkeys()))])\n\u001b[0;32m   6302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_examples):\n\u001b[1;32m-> 6303\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m   6304\u001b[0m     additional_args \u001b[38;5;241m=\u001b[39m ()\n\u001b[0;32m   6305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m with_indices:\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:6303\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   6301\u001b[0m num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch\u001b[38;5;241m.\u001b[39mkeys()))])\n\u001b[0;32m   6302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_examples):\n\u001b[1;32m-> 6303\u001b[0m     example \u001b[38;5;241m=\u001b[39m {key: \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m[i] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch}\n\u001b[0;32m   6304\u001b[0m     additional_args \u001b[38;5;241m=\u001b[39m ()\n\u001b[0;32m   6305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m with_indices:\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:279\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    277\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key]\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format:\n\u001b[1;32m--> 279\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format\u001b[38;5;241m.\u001b[39mremove(key)\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:382\u001b[0m, in \u001b[0;36mLazyBatch.format\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:449\u001b[0m, in \u001b[0;36mPythonFormatter.format_column\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    448\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_column(pa_table)\n\u001b[1;32m--> 449\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:224\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_column\u001b[1;34m(self, column, column_name)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mdecode_example(row) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, column: \u001b[38;5;28mlist\u001b[39m, column_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mdecode_column(column, column_name) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m column\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def filter_short(batch):\n",
    "    return len(batch[\"input_ids\"]) > 10 and batch[\"speech\"].shape[0] > 1600  # Al menos 0.1 segundos de audio\n",
    "\n",
    "filtered_dataset = tokenized_dataset.filter(filter_short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e13181f14cc4c388a7d6cf9cfede4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/179 shards):   0%|          | 0/230467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset.save_to_disk('./tokenized_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta actual: c:\\Proyectos\\Film_recomendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962688478c454c2ea8640160ecc84aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'speech', 'sampling_rate', 'input_ids'],\n",
      "    num_rows: 230467\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import os\n",
    "# Obtener la ruta actual\n",
    "current_path = os.getcwd()\n",
    "print(f\"Ruta actual: {current_path}\")\n",
    "\n",
    "# Especificar el nombre del directorio para guardar/cargar el dataset\n",
    "dataset_path = os.path.join(current_path, \"tokenized_dataset\")\n",
    "\n",
    "# Cargar el dataset tokenizado\n",
    "tokenized_dataset = load_from_disk(dataset_path)\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: 29\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m tokenized_dataset:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspeech\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for example in tokenized_dataset:\n",
    "    print(f\"input_ids shape: {len(example['input_ids'])}\")\n",
    "    print(f\"speech shape: {example['speech'].shape}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=5e-5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=processor)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,  # Agregar el collator\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
